# üöÄ Active Java Messaging Service

### A Fault-Tolerant, Partitioned, Durable, High-Throughput Message Broker Built on PostgreSQL

This project implements a **Kafka-like message broker in pure Java**, using **PostgreSQL advisory locks**, **partition claims**, **retry & DLQ**, **backpressure**, and **parallel workers** ‚Äî without Kafka, RabbitMQ, or Redis.

Designed for:

* WhatsApp Chatbot Processing Pipelines
* Event-driven Microservices
* ETL / Workflow Orchestration
* Guaranteed delivery with retries + DLQ
* Cloud or on-prem setups where Kafka is unavailable

Powered by:

* **Spring Boot 3.5+**
* **Java 25**
* **PostgreSQL 14+**
* **Micrometer / Prometheus**
* **Spring JDBC**

---

# ‚≠ê Features

### ‚úî Guaranteed‚ÄêDelivery Message Broker

Backed by Postgres tables (`broker_messages`, `consumer_offsets`, `broker_dlq`).

### ‚úî Partitioning Like Kafka

Producers assign messages to partitions via hash or custom partitioning logic.
Consumers claim partitions via Postgres **advisory locks**.

### ‚úî Horizontal Scalability

Multiple instances of the same consumer group auto-balance partitions.

### ‚úî Retries + Exponential Backoff + DLQ

Built-in:

* Retry counter
* Exponential backoff
* Move to DLQ table after `maxAttempts`

### ‚úî High Concurrency

Workers run in:

* Cached thread pool
* Partition workers per consumer group
* Atomic partition locking

### ‚úî Pure Java, Zero External Brokers Needed

No Kafka, no Redis, no Zookeeper.

### ‚úî Observability

* Publish latency
* Process success/failure counts
* DLQ counts
* Consumer count
* Prometheus metrics via actuator

---

# üèóÔ∏è Architecture Overview

```
Producer ‚Üí broker_messages (Postgres) ‚Üí Consumers ‚Üí DLQ (if failed)
           ^ advisory locks for partitions ^
```

**Incoming flow:**

1. `IncomingMessageService` stores incoming Twilio/WhatsApp message ‚Üí publishes to broker.
2. Broker assigns message to partition.
3. Consumer runtime:

    * Claims partitions using advisory locks.
    * Polls `broker_messages`.
    * Calls your `MessageProcessor`.
    * Writes offsets and final status.

---

# üì¶ Required Database Schema

Run these SQL migrations before starting the application:

```sql
CREATE TABLE broker_messages (
    id BIGSERIAL PRIMARY KEY,
    topic VARCHAR(255) NOT NULL,
    partition INT NOT NULL,
    key VARCHAR(255),
    payload JSONB NOT NULL,
    status VARCHAR(32) NOT NULL,
    attempts INT DEFAULT 0,
    available_at TIMESTAMP DEFAULT now()
);

CREATE TABLE consumer_offsets (
    topic VARCHAR(255) NOT NULL,
    group_id VARCHAR(255) NOT NULL,
    partition INT NOT NULL,
    last_consumed_id BIGINT DEFAULT 0,
    updated_at TIMESTAMP DEFAULT now(),
    PRIMARY KEY (topic, group_id, partition)
);

CREATE TABLE broker_dlq (
    id BIGSERIAL PRIMARY KEY,
    original_message_id BIGINT,
    topic VARCHAR(255),
    partition INT,
    key VARCHAR(255),
    payload JSONB,
    error TEXT,
    attempts INT,
    created_at TIMESTAMP DEFAULT now()
);
```

Indexes (recommended):

```sql
CREATE INDEX idx_broker_messages_ready 
    ON broker_messages(topic, partition, status, available_at);

CREATE INDEX idx_broker_messages_available 
    ON broker_messages(available_at);
```

---

# ‚öôÔ∏è Required Application Properties

Add to `application.yml`:

```yaml
broker:
  partitions: 8

  consumer:
    group: whatsapp-processor
    workers: 4
    batch-size: 20
    max-attempts: 5
    base-backoff-millis: 500
    max-backoff-millis: 30000
    idle-delay-millis: 200
    poll-interval-ms: 500

management:
  endpoints:
    web:
      exposure:
        include: health, info, prometheus
  endpoint:
    health:
      show-details: when_authorized
  metrics:
    export:
      prometheus:
        enabled: true

spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/infraimatic
    username: infra
    password: infra_password
    driver-class-name: org.postgresql.Driver
```

---

# üß© How to Use in Your Application

## 1. Produce Messages (send to topic)

Use `IncomingMessageService`:

```java
incomingMessageService.handleIncoming(payload);
```

This will:

1. Save your business entity (MessageEntity)
2. Publish to broker topic `"whatsapp.incoming"`

---

## 2. Consume Messages (automatic parallel processing)

Your consumer automatically starts after the application boots:

```java
@Component
public class IncomingMessageConsumer {
    @EventListener(ApplicationStartedEvent.class)
    public void onStarted() {
        broker.startConsumer(topic, groupId, processor, props);
    }
}
```

Broker calls your `MessageProcessor`:

```java
@Component
public class WhatsAppProcessor implements MessageProcessor {

    @Override
    public void process(Map<String, String> payload) {
        // Implement message business logic here
        // Throw exception to trigger retry
    }
}
```

---

# üß™ Testing with Postgres Locally

Use Docker:

```bash
docker run -p 5432:5432 \
  -e POSTGRES_USER=infra \
  -e POSTGRES_PASSWORD=infra_password \
  -e POSTGRES_DB=infraimatic \
  postgres:16
```

Then create schema using SQL above.

---

# üõ†Ô∏è Tuning & Performance

| Parameter                 | Effect                             |
| ------------------------- | ---------------------------------- |
| `broker.partitions`       | More partitions = more parallelism |
| `broker.consumer.workers` | More threads per instance          |
| `max-attempts`            | Retry attempts before DLQ          |
| `base-backoff-millis`     | Retry backoff multiplier           |
| `idle-delay-millis`       | Delay when no messages found       |

Recommended starting values:

* partitions: **8**
* workers: **4**
* batch-size: **20**
* max-attempts: **5**
* CPU threads √ó 2 rule for worker total

---

# ü©π Error Handling

Broker automatically handles:

### ‚úî JSON parse errors ‚Üí DLQ

### ‚úî Processor exceptions ‚Üí retry with backoff

### ‚úî Max attempts exceeded ‚Üí DLQ

### ‚úî Partition lock lost ‚Üí worker reclaims automatically

---

# üõ°Ô∏è Observability & Metrics

Available metrics:

| Metric                    | Meaning                          |
| ------------------------- | -------------------------------- |
| `broker.publish.duration` | Message publish time             |
| `broker.process.success`  | Successful message process count |
| `broker.process.failure`  | Failed message process count     |
| `broker.consumer.count`   | Running consumers                |
| `broker.dlq.sent`         | Messages moved to DLQ            |

Prometheus endpoint:

```
GET /actuator/prometheus
```

---

# üß± Project Structure

```
src/main/java
  ‚îú‚îÄ broker/
  ‚îÇ   ‚îú‚îÄ JdbcMessageBroker.java
  ‚îÇ   ‚îú‚îÄ MessageBroker.java
  ‚îÇ   ‚îú‚îÄ MessageProcessor.java
  ‚îÇ   ‚îú‚îÄ ConsumerProperties.java
  ‚îÇ   ‚îî‚îÄ ConsumerHandle.java
  ‚îú‚îÄ whatsapp/
      ‚îú‚îÄ IncomingMessageService.java
      ‚îú‚îÄ IncomingMessageConsumer.java
      ‚îî‚îÄ MessageProcessorImplementation.java
```

---

# ‚úî Production Checklist

* [ ] Postgres max connections tuned (>= 200)
* [ ] `broker_messages` table partitioned (optional large-scale)
* [ ] CPU threads ‚â• workers √ó consumer threads
* [ ] Prometheus/Grafana installed
* [ ] DLQ alerts configured

---

If you want, I can also generate:

‚úÖ A full `docker-compose.yml` (App + Postgres + pgAdmin)
‚úÖ A DB migration (Liquibase / Flyway) for all broker tables
‚úÖ A Grafana dashboard for broker metrics
‚úÖ Autoscaling tips & production tuning guide

Just tell me!
